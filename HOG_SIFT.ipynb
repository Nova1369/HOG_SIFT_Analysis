{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac54935",
   "metadata": {},
   "source": [
    "# Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b846cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob as gb\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping ,ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D , Dense , Dropout , Flatten ,MaxPooling2D , BatchNormalization ,experimental\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from skimage.feature import hog\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0 # Normalize pixel values to␣\n",
    "↪[0, 1]\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG-16 model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32,3)) \n",
    "\n",
    "# MNIST images are 28x28, so resize them to 32x32\n",
    "vgg_model.trainable = False \n",
    "\n",
    "# Freeze the weights\n",
    "def extract_deep_features(images):\n",
    "print('Extracting deep features')\n",
    "images = np.expand_dims(images, axis=-1) \n",
    "\n",
    "# Add channel dimension for grayscale images\n",
    "images = np.repeat(images, 3, axis=-1) # Convert grayscale to RGB\n",
    "images = np.array([tf.image.resize(image, (32, 32)) for image in images])\n",
    "\n",
    "# Resize images to 32x32\n",
    "deep_features = vgg_model.predict(images)\n",
    "return deep_features\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    print('Extracting deep features')\n",
    "    hog_features = []\n",
    "    for image in images:\n",
    "    hog_feature = hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False)\n",
    "    hog_features.append(hog_feature)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "# Extract deep features for training and test sets\n",
    "X_train_deep_features = extract_deep_features(X_train)\n",
    "X_test_deep_features = extract_deep_features(X_test)\n",
    "\n",
    "# Extract HOG features for training and test sets\n",
    "X_train_hog_features = extract_hog_features(X_train)\n",
    "X_test_hog_features = extract_hog_features(X_test)\n",
    "\n",
    "# Stack deep features with HOG features\n",
    "X_train_stacked = np.concatenate((X_train_deep_features.reshape(len(X_train_deep_features), -1), X_train_hog_features), axis=1)\n",
    "X_test_stacked = np.concatenate((X_test_deep_features.reshape(len(X_test_deep_features), -1), X_test_hog_features), axis=1)\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Run the hybrid model 5 times and compute the mean accuracy\n",
    "accuracies = []\n",
    "for _ in range(2):\n",
    "    # Split the data into training and validation sets\n",
    "    X_train_split, X_val, y_train_split, y_val = train_test_split(X_train_stacked, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    print('fitting rf model')\n",
    "    rf_classifier.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    val_predictions = rf_classifier.predict(X_val)\n",
    "    print('getting predictions')\n",
    "    accuracy = accuracy_score(y_val, val_predictions)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(\"Mean accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63f3d40",
   "metadata": {},
   "source": [
    "# Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.applications import VGG16\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess MNIST images\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Resize MNIST images to match VGG input size\n",
    "X_train_resized = np.array([cv2.resize(img, (48, 48)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (48, 48)) for img in X_test])\n",
    "\n",
    "# Extract deep features from VGG-16 model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48,3))\n",
    "\n",
    "def extract_vgg_features(images):\n",
    "    images = np.repeat(images[..., np.newaxis], 3, -1) # Convert to RGB\n",
    "    features = vgg_model.predict(images)\n",
    "    features_flattened = features.reshape(features.shape[0], -1)\n",
    "    return features_flattened\n",
    "\n",
    "X_train_vgg_features = extract_vgg_features(X_train_resized)\n",
    "X_test_vgg_features = extract_vgg_features(X_test_resized)\n",
    "\n",
    "# Extract SIFT features from MNIST images\n",
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_features = []\n",
    "    for img in images:\n",
    "        img_uint8 = cv2.convertScaleAbs(img) # Convert to CV_8U format\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_uint8, None)\n",
    "        if descriptors is not None:\n",
    "            sift_features.append(descriptors.flatten())\n",
    "        else:\n",
    "            sift_features.append(np.zeros(128)) # If no keypoints detected,append zeros\n",
    "    return np.array(sift_features)\n",
    "\n",
    "X_train_sift_features = extract_sift_features(X_train)\n",
    "X_test_sift_features = extract_sift_features(X_test)\n",
    "\n",
    "# Stack deep features with SIFT features\n",
    "X_train_stacked = np.hstack((X_train_vgg_features, X_train_sift_features))\n",
    "X_test_stacked = np.hstack((X_test_vgg_features, X_test_sift_features))\n",
    "\n",
    "# Train RandomForest classifier\n",
    "mean_accuracy = 0\n",
    "for i in range(5):\n",
    "    # Split data into train and validation sets\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_stacked, y_train, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Train RandomForest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = clf.predict(X_val_split)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_val_split, y_pred)\n",
    "    mean_accuracy += accuracy\n",
    "\n",
    "mean_accuracy /= 5\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c27a9",
   "metadata": {},
   "source": [
    "# Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fb5dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.applications import VGG16\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess MNIST images\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Resize MNIST images to match VGG input size\n",
    "X_train_resized = np.array([cv2.resize(img, (48, 48)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (48, 48)) for img in X_test])\n",
    "\n",
    "# Extract deep features from VGG-16 model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48,3))\n",
    "\n",
    "def extract_vgg_features(images):\n",
    "    images = np.repeat(images[..., np.newaxis], 3, -1) # Convert to RGB\n",
    "    features = vgg_model.predict(images)\n",
    "    features_flattened = features.reshape(features.shape[0], -1)\n",
    "    return features_flattened\n",
    "\n",
    "X_train_vgg_features = extract_vgg_features(X_train_resized)\n",
    "X_test_vgg_features = extract_vgg_features(X_test_resized)\n",
    "\n",
    "# Extract SIFT features from MNIST images\n",
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_features = []\n",
    "    for img in images:\n",
    "        img_uint8 = cv2.convertScaleAbs(img) # Convert to CV_8U format\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_uint8, None)\n",
    "        if descriptors is not None:\n",
    "            sift_features.append(descriptors.flatten())\n",
    "        else:\n",
    "            sift_features.append(np.zeros(128)) # If no keypoints detected,append zeros\n",
    "    return np.array(sift_features)\n",
    "\n",
    "X_train_sift_features = extract_sift_features(X_train)\n",
    "X_test_sift_features = extract_sift_features(X_test)\n",
    "\n",
    "# Extract HOG features from MNIST images\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "        hog_feat = hog(img, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(1, 1), block_norm='L2-Hys')\n",
    "        hog_features.append(hog_feat)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "X_train_hog_features = extract_hog_features(X_train)\n",
    "X_test_hog_features = extract_hog_features(X_test)\n",
    "\n",
    "# Stack deep features with SIFT and HOG features\n",
    "X_train_stacked = np.hstack((X_train_vgg_features, X_train_sift_features, X_train_hog_features))\n",
    "X_test_stacked = np.hstack((X_test_vgg_features, X_test_sift_features, X_test_hog_features))\n",
    "\n",
    "# Train RandomForest classifier\n",
    "mean_accuracy = 0\n",
    "for i in range(5):\n",
    "    # Split data into train and validation sets\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_stacked, y_train, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # Train RandomForest classifier\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = clf.predict(X_val_split)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_val_split, y_pred)\n",
    "    mean_accuracy += accuracy\n",
    "\n",
    "mean_accuracy /= 5\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc8e3f",
   "metadata": {},
   "source": [
    "# Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f49fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.applications import VGG16\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import hog\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess MNIST images\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Resize MNIST images to match VGG input size\n",
    "X_train_resized = np.array([cv2.resize(img, (48, 48)) for img in X_train])\n",
    "X_test_resized = np.array([cv2.resize(img, (48, 48)) for img in X_test])\n",
    "\n",
    "# Extract deep features from VGG-16 model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48,3))\n",
    "\n",
    "def extract_vgg_features(images):\n",
    "    images = np.repeat(images[..., np.newaxis], 3, -1) # Convert to RGB\n",
    "    features = vgg_model.predict(images)\n",
    "    features_flattened = features.reshape(features.shape[0], -1)\n",
    "    return features_flattened\n",
    "\n",
    "X_train_vgg_features = extract_vgg_features(X_train_resized)\n",
    "X_test_vgg_features = extract_vgg_features(X_test_resized)\n",
    "\n",
    "# Extract SIFT features from MNIST images\n",
    "def extract_sift_features(images):\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_features = []\n",
    "    for img in images:\n",
    "        img_uint8 = cv2.convertScaleAbs(img) # Convert to CV_8U format\n",
    "        keypoints, descriptors = sift.detectAndCompute(img_uint8, None)\n",
    "        if descriptors is not None:\n",
    "            sift_features.append(descriptors.flatten())\n",
    "        else:\n",
    "            sift_features.append(np.zeros(128)) # If no keypoints detected, append zeros\n",
    "    return np.array(sift_features)\n",
    "\n",
    "X_train_sift_features = extract_sift_features(X_train)\n",
    "X_test_sift_features = extract_sift_features(X_test)\n",
    "\n",
    "# Extract HOG features from MNIST images\n",
    "def extract_hog_features(images):\n",
    "    hog_features = []\n",
    "    for img in images:\n",
    "    hog_feat = hog(img, orientations=8, pixels_per_cell=(4, 4), cells_per_block=(1, 1), block_norm='L2-Hys')\n",
    "    hog_features.append(hog_feat)\n",
    "    return np.array(hog_features)\n",
    "\n",
    "X_train_hog_features = extract_hog_features(X_train)\n",
    "X_test_hog_features = extract_hog_features(X_test)\n",
    "\n",
    "# Stack deep features with SIFT and HOG features\n",
    "X_train_stacked = np.hstack((X_train_vgg_features, X_train_sift_features, X_train_hog_features))\n",
    "X_test_stacked = np.hstack((X_test_vgg_features, X_test_sift_features, X_test_hog_features))\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "components_list = [50, 100, 150] # Try different component values\n",
    "mean_accuracy_list = []\n",
    "\n",
    "for n_components in components_list:\n",
    "    mean_accuracy = 0\n",
    "    for i in range(5):\n",
    "        # Split data into train and validation sets\n",
    "        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_stacked, y_train, test_size=0.2, random_state=i)\n",
    "\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_train_pca = pca.fit_transform(X_train_split)\n",
    "        X_val_pca = pca.transform(X_val_split)\n",
    "        \n",
    "        # Train RandomForest classifier with hyperparameter tuning\n",
    "        clf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=2, random_state=42)\n",
    "        clf.fit(X_train_pca, y_train_split)\n",
    "        \n",
    "        # Predict on validation set\n",
    "        y_pred = clf.predict(X_val_pca)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = accuracy_score(y_val_split, y_pred)\n",
    "        mean_accuracy += accuracy\n",
    "        \n",
    "    mean_accuracy /= 5\n",
    "    mean_accuracy_list.append(mean_accuracy)\n",
    "    print(f\"Mean Accuracy (PCA Components={n_components}): {mean_accuracy}\")\n",
    "    \n",
    "# Choose the best component value based on validation performance\n",
    "best_components = components_list[np.argmax(mean_accuracy_list)]\n",
    "\n",
    "# Run the model with the best components 5 times and compute the mean accuracy\n",
    "mean_accuracy_final = 0\n",
    "for i in range(5):\n",
    "    # Split data into train and validation sets\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_stacked, y_train, test_size=0.2, random_state=1)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=best_components)\n",
    "    X_train_pca = pca.fit_transform(X_train_split)\n",
    "    X_val_pca = pca.transform(X_val_split)\n",
    "    \n",
    "    # Train RandomForest classifier with hyperparameter tuning\n",
    "    clf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=2, random_state=42)\n",
    "    clf.fit(X_train_pca, y_train_split)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = clf.predict(X_val_pca)\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(y_val_split, y_pred)\n",
    "    mean_accuracy_final += accuracy\n",
    "\n",
    "mean_accuracy_final /= 5\n",
    "print(f\"Mean Accuracy (PCA Components={best_components}): {mean_accuracy_final}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
